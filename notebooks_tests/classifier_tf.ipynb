{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to store labels? 0 to 3, binary array, or string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "source": [
    "Import, save and split data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = ['sine', 'square','sawtooth','burst']\n",
    "df = pd.read_csv('full_data.csv', header=None)\n",
    "#df = pd.read_csv('data_1024.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(640, 324)"
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    0     1     2     3      4      5     6     7      8     9    ...   314  \\\n0   0.0   0.0   0.0   0.0    0.0    0.0   0.0   0.0    0.0   0.0  ...   0.0   \n1   0.0   0.0   0.0   0.0    0.0   62.0   0.0   0.0    0.0   0.0  ...   0.0   \n2  14.0  30.0  60.0  56.0  120.0  112.0  96.0  97.0   65.0  67.0  ...   3.0   \n3  36.0  32.0  36.0  32.0   32.0   32.0   4.0   4.0   36.0   4.0  ...   0.0   \n4   0.0  30.0   0.0   0.0    3.0   64.0   0.0   0.0  112.0   0.0  ...  64.0   \n\n    315    316    317   318   319  320  321  322  323  \n0   0.0  126.0    0.0   0.0   0.0  0.0  0.0  0.0  1.0  \n1   0.0   15.0    0.0   0.0   0.0  0.0  1.0  0.0  0.0  \n2   7.0    7.0   15.0  30.0  28.0  0.0  1.0  0.0  0.0  \n3  32.0   36.0   32.0  32.0  32.0  1.0  0.0  0.0  0.0  \n4   0.0    0.0  120.0   0.0   0.0  0.0  0.0  1.0  0.0  \n\n[5 rows x 324 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>314</th>\n      <th>315</th>\n      <th>316</th>\n      <th>317</th>\n      <th>318</th>\n      <th>319</th>\n      <th>320</th>\n      <th>321</th>\n      <th>322</th>\n      <th>323</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>126.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>62.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14.0</td>\n      <td>30.0</td>\n      <td>60.0</td>\n      <td>56.0</td>\n      <td>120.0</td>\n      <td>112.0</td>\n      <td>96.0</td>\n      <td>97.0</td>\n      <td>65.0</td>\n      <td>67.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>15.0</td>\n      <td>30.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36.0</td>\n      <td>32.0</td>\n      <td>36.0</td>\n      <td>32.0</td>\n      <td>32.0</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>36.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>32.0</td>\n      <td>36.0</td>\n      <td>32.0</td>\n      <td>32.0</td>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>64.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>112.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>64.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 324 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(df.columns[-4:],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(640, 320)"
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), -4)' is an invalid key",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-7cc98de6f29b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#df[df[100]>15 and df[200]<10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_robin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-196-7cc98de6f29b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#df[df[100]>15 and df[200]<10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mY_robin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2887\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2891\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), -4)' is an invalid key"
     ]
    }
   ],
   "source": [
    "Y = df.iloc[:,-4:].values\n",
    "#df[df[100]>15 and df[200]<10]\n",
    "Y_robin = [df[val].values for val in range(-4,0)]\n",
    "print(Y)\n",
    "print(\"---\")\n",
    "print(np.array(Y_robin).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       ...,\n       [1., 0., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(640, 4)"
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(512, 320)"
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scaler??   "
   ]
  },
  {
   "source": [
    "First Model - \n",
    "- using sigmoid for outputs\n",
    "- 80 epochs\n",
    "- layer1 = 100\n",
    "- layer2 = 50"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,activation='sigmoid'))\n",
    "model.add(Dense(50,activation='sigmoid'))\n",
    "model.add(Dense(20,activation='sigmoid'))\n",
    "model.add(Dense(4,activation='sigmoid')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n5/5 [==============================] - 0s 52ms/step - loss: 1.3971 - accuracy: 0.2500 - val_loss: 1.3929 - val_accuracy: 0.2500\nEpoch 2/100\n5/5 [==============================] - 0s 11ms/step - loss: 1.3671 - accuracy: 0.2500 - val_loss: 1.3813 - val_accuracy: 0.2500\nEpoch 3/100\n5/5 [==============================] - 0s 16ms/step - loss: 1.3484 - accuracy: 0.3375 - val_loss: 1.3700 - val_accuracy: 0.4500\nEpoch 4/100\n5/5 [==============================] - 0s 15ms/step - loss: 1.3349 - accuracy: 0.5750 - val_loss: 1.3607 - val_accuracy: 0.4750\nEpoch 5/100\n5/5 [==============================] - 0s 16ms/step - loss: 1.3176 - accuracy: 0.6812 - val_loss: 1.3517 - val_accuracy: 0.4250\nEpoch 6/100\n5/5 [==============================] - 0s 16ms/step - loss: 1.3013 - accuracy: 0.5938 - val_loss: 1.3432 - val_accuracy: 0.4000\nEpoch 7/100\n5/5 [==============================] - 0s 13ms/step - loss: 1.2854 - accuracy: 0.6125 - val_loss: 1.3339 - val_accuracy: 0.4000\nEpoch 8/100\n5/5 [==============================] - 0s 17ms/step - loss: 1.2675 - accuracy: 0.6187 - val_loss: 1.3252 - val_accuracy: 0.3750\nEpoch 9/100\n5/5 [==============================] - 0s 12ms/step - loss: 1.2492 - accuracy: 0.5750 - val_loss: 1.3160 - val_accuracy: 0.3750\nEpoch 10/100\n5/5 [==============================] - 0s 13ms/step - loss: 1.2321 - accuracy: 0.6250 - val_loss: 1.3069 - val_accuracy: 0.4000\nEpoch 11/100\n5/5 [==============================] - 0s 15ms/step - loss: 1.2143 - accuracy: 0.6187 - val_loss: 1.3002 - val_accuracy: 0.3750\nEpoch 12/100\n5/5 [==============================] - 0s 15ms/step - loss: 1.1948 - accuracy: 0.6625 - val_loss: 1.2884 - val_accuracy: 0.3750\nEpoch 13/100\n5/5 [==============================] - 0s 16ms/step - loss: 1.1741 - accuracy: 0.6313 - val_loss: 1.2722 - val_accuracy: 0.3750\nEpoch 14/100\n5/5 [==============================] - 0s 13ms/step - loss: 1.1544 - accuracy: 0.6562 - val_loss: 1.2609 - val_accuracy: 0.4000\nEpoch 15/100\n5/5 [==============================] - 0s 13ms/step - loss: 1.1334 - accuracy: 0.6562 - val_loss: 1.2503 - val_accuracy: 0.4000\nEpoch 16/100\n5/5 [==============================] - 0s 15ms/step - loss: 1.1176 - accuracy: 0.7000 - val_loss: 1.2443 - val_accuracy: 0.4000\nEpoch 17/100\n5/5 [==============================] - 0s 13ms/step - loss: 1.0993 - accuracy: 0.6625 - val_loss: 1.2294 - val_accuracy: 0.3750\nEpoch 18/100\n5/5 [==============================] - 0s 14ms/step - loss: 1.0806 - accuracy: 0.7000 - val_loss: 1.2287 - val_accuracy: 0.4000\nEpoch 19/100\n5/5 [==============================] - 0s 22ms/step - loss: 1.0629 - accuracy: 0.7250 - val_loss: 1.2146 - val_accuracy: 0.4000\nEpoch 20/100\n5/5 [==============================] - 0s 14ms/step - loss: 1.0460 - accuracy: 0.7500 - val_loss: 1.2021 - val_accuracy: 0.3750\nEpoch 21/100\n5/5 [==============================] - 0s 12ms/step - loss: 1.0277 - accuracy: 0.7250 - val_loss: 1.1881 - val_accuracy: 0.4000\nEpoch 22/100\n5/5 [==============================] - 0s 14ms/step - loss: 1.0100 - accuracy: 0.7312 - val_loss: 1.1759 - val_accuracy: 0.4250\nEpoch 23/100\n5/5 [==============================] - 0s 19ms/step - loss: 0.9947 - accuracy: 0.7437 - val_loss: 1.1621 - val_accuracy: 0.4000\nEpoch 24/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.9777 - accuracy: 0.7812 - val_loss: 1.1549 - val_accuracy: 0.4250\nEpoch 25/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.9619 - accuracy: 0.7688 - val_loss: 1.1442 - val_accuracy: 0.4000\nEpoch 26/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.9469 - accuracy: 0.8062 - val_loss: 1.1360 - val_accuracy: 0.4250\nEpoch 27/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.9314 - accuracy: 0.8062 - val_loss: 1.1261 - val_accuracy: 0.4250\nEpoch 28/100\n5/5 [==============================] - 0s 19ms/step - loss: 0.9169 - accuracy: 0.7625 - val_loss: 1.1197 - val_accuracy: 0.4500\nEpoch 29/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.9002 - accuracy: 0.8125 - val_loss: 1.1165 - val_accuracy: 0.4750\nEpoch 30/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.8872 - accuracy: 0.8062 - val_loss: 1.1110 - val_accuracy: 0.4500\nEpoch 31/100\n5/5 [==============================] - 0s 17ms/step - loss: 0.8723 - accuracy: 0.8375 - val_loss: 1.0963 - val_accuracy: 0.4750\nEpoch 32/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.8583 - accuracy: 0.7937 - val_loss: 1.1002 - val_accuracy: 0.3750\nEpoch 33/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.8449 - accuracy: 0.8562 - val_loss: 1.0852 - val_accuracy: 0.3750\nEpoch 34/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.8304 - accuracy: 0.8375 - val_loss: 1.0830 - val_accuracy: 0.4750\nEpoch 35/100\n5/5 [==============================] - 0s 12ms/step - loss: 0.8161 - accuracy: 0.8750 - val_loss: 1.0909 - val_accuracy: 0.4250\nEpoch 36/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.8053 - accuracy: 0.8625 - val_loss: 1.0677 - val_accuracy: 0.5000\nEpoch 37/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.7906 - accuracy: 0.8313 - val_loss: 1.0645 - val_accuracy: 0.4750\nEpoch 38/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.7779 - accuracy: 0.8375 - val_loss: 1.0740 - val_accuracy: 0.4500\nEpoch 39/100\n5/5 [==============================] - 0s 12ms/step - loss: 0.7627 - accuracy: 0.8938 - val_loss: 1.0768 - val_accuracy: 0.4250\nEpoch 40/100\n5/5 [==============================] - 0s 12ms/step - loss: 0.7490 - accuracy: 0.8438 - val_loss: 1.0728 - val_accuracy: 0.4500\nEpoch 41/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.7385 - accuracy: 0.8562 - val_loss: 1.0720 - val_accuracy: 0.3750\nEpoch 42/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.7242 - accuracy: 0.8687 - val_loss: 1.0774 - val_accuracy: 0.3750\nEpoch 43/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.7118 - accuracy: 0.8625 - val_loss: 1.0846 - val_accuracy: 0.4000\nEpoch 44/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.7027 - accuracy: 0.8625 - val_loss: 1.0636 - val_accuracy: 0.3750\nEpoch 45/100\n5/5 [==============================] - 0s 18ms/step - loss: 0.6886 - accuracy: 0.8438 - val_loss: 1.0654 - val_accuracy: 0.4000\nEpoch 46/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.6791 - accuracy: 0.8313 - val_loss: 1.0773 - val_accuracy: 0.4250\nEpoch 47/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.6655 - accuracy: 0.8750 - val_loss: 1.0572 - val_accuracy: 0.4250\nEpoch 48/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.6535 - accuracy: 0.8750 - val_loss: 1.0507 - val_accuracy: 0.4000\nEpoch 49/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.6420 - accuracy: 0.8625 - val_loss: 1.0559 - val_accuracy: 0.4250\nEpoch 50/100\n5/5 [==============================] - 0s 22ms/step - loss: 0.6310 - accuracy: 0.8687 - val_loss: 1.0601 - val_accuracy: 0.4500\nEpoch 51/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.6194 - accuracy: 0.8875 - val_loss: 1.0548 - val_accuracy: 0.4500\nEpoch 52/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.6082 - accuracy: 0.8687 - val_loss: 1.0459 - val_accuracy: 0.4250\nEpoch 53/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.5970 - accuracy: 0.8875 - val_loss: 1.0570 - val_accuracy: 0.4250\nEpoch 54/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.5882 - accuracy: 0.8562 - val_loss: 1.0626 - val_accuracy: 0.4250\nEpoch 55/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.5764 - accuracy: 0.8938 - val_loss: 1.0584 - val_accuracy: 0.4250\nEpoch 56/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.5652 - accuracy: 0.8813 - val_loss: 1.0535 - val_accuracy: 0.4000\nEpoch 57/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.5552 - accuracy: 0.8938 - val_loss: 1.0808 - val_accuracy: 0.4000\nEpoch 58/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.5470 - accuracy: 0.8625 - val_loss: 1.0848 - val_accuracy: 0.4000\nEpoch 59/100\n5/5 [==============================] - 0s 12ms/step - loss: 0.5371 - accuracy: 0.8813 - val_loss: 1.0685 - val_accuracy: 0.3500\nEpoch 60/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.5353 - accuracy: 0.8625 - val_loss: 1.0787 - val_accuracy: 0.3750\nEpoch 61/100\n5/5 [==============================] - 0s 18ms/step - loss: 0.5218 - accuracy: 0.9062 - val_loss: 1.0485 - val_accuracy: 0.3750\nEpoch 62/100\n5/5 [==============================] - 0s 18ms/step - loss: 0.5151 - accuracy: 0.8750 - val_loss: 1.0612 - val_accuracy: 0.3500\nEpoch 63/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.5013 - accuracy: 0.8687 - val_loss: 1.0621 - val_accuracy: 0.3500\nEpoch 64/100\n5/5 [==============================] - 0s 17ms/step - loss: 0.4942 - accuracy: 0.8938 - val_loss: 1.0562 - val_accuracy: 0.3750\nEpoch 65/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.4896 - accuracy: 0.8938 - val_loss: 1.0352 - val_accuracy: 0.4250\nEpoch 66/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.4740 - accuracy: 0.9000 - val_loss: 1.0441 - val_accuracy: 0.3500\nEpoch 67/100\n5/5 [==============================] - 0s 12ms/step - loss: 0.4681 - accuracy: 0.8750 - val_loss: 1.0284 - val_accuracy: 0.4250\nEpoch 68/100\n5/5 [==============================] - 0s 19ms/step - loss: 0.4624 - accuracy: 0.9000 - val_loss: 1.0757 - val_accuracy: 0.4000\nEpoch 69/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.4518 - accuracy: 0.8750 - val_loss: 1.0637 - val_accuracy: 0.4250\nEpoch 70/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.4394 - accuracy: 0.8875 - val_loss: 1.0254 - val_accuracy: 0.4250\nEpoch 71/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.4340 - accuracy: 0.8813 - val_loss: 1.0519 - val_accuracy: 0.4000\nEpoch 72/100\n5/5 [==============================] - 0s 18ms/step - loss: 0.4245 - accuracy: 0.8875 - val_loss: 1.0723 - val_accuracy: 0.4500\nEpoch 73/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.4169 - accuracy: 0.9000 - val_loss: 1.0522 - val_accuracy: 0.4000\nEpoch 74/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.4088 - accuracy: 0.9312 - val_loss: 1.0612 - val_accuracy: 0.4750\nEpoch 75/100\n5/5 [==============================] - 0s 18ms/step - loss: 0.3993 - accuracy: 0.9187 - val_loss: 1.0753 - val_accuracy: 0.4750\nEpoch 76/100\n5/5 [==============================] - 0s 18ms/step - loss: 0.3933 - accuracy: 0.9250 - val_loss: 1.0926 - val_accuracy: 0.4000\nEpoch 77/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.3910 - accuracy: 0.9062 - val_loss: 1.0820 - val_accuracy: 0.4500\nEpoch 78/100\n5/5 [==============================] - 0s 17ms/step - loss: 0.3751 - accuracy: 0.9187 - val_loss: 1.0737 - val_accuracy: 0.4750\nEpoch 79/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.3631 - accuracy: 0.9312 - val_loss: 1.0903 - val_accuracy: 0.4500\nEpoch 80/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.3593 - accuracy: 0.9375 - val_loss: 1.0936 - val_accuracy: 0.4750\nEpoch 81/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.3536 - accuracy: 0.9250 - val_loss: 1.0893 - val_accuracy: 0.4500\nEpoch 82/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.3467 - accuracy: 0.9062 - val_loss: 1.1058 - val_accuracy: 0.4750\nEpoch 83/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.3351 - accuracy: 0.9375 - val_loss: 1.1422 - val_accuracy: 0.4500\nEpoch 84/100\n5/5 [==============================] - 0s 17ms/step - loss: 0.3304 - accuracy: 0.9438 - val_loss: 1.1761 - val_accuracy: 0.4500\nEpoch 85/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.3351 - accuracy: 0.9125 - val_loss: 1.1903 - val_accuracy: 0.4000\nEpoch 86/100\n5/5 [==============================] - 0s 13ms/step - loss: 0.3245 - accuracy: 0.9375 - val_loss: 1.2050 - val_accuracy: 0.4750\nEpoch 87/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.3196 - accuracy: 0.9438 - val_loss: 1.1987 - val_accuracy: 0.4750\nEpoch 88/100\n5/5 [==============================] - 0s 19ms/step - loss: 0.3087 - accuracy: 0.9625 - val_loss: 1.1836 - val_accuracy: 0.3750\nEpoch 89/100\n5/5 [==============================] - 0s 19ms/step - loss: 0.2971 - accuracy: 0.9625 - val_loss: 1.2060 - val_accuracy: 0.4000\nEpoch 90/100\n5/5 [==============================] - 0s 17ms/step - loss: 0.2873 - accuracy: 0.9688 - val_loss: 1.1958 - val_accuracy: 0.4750\nEpoch 91/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.2938 - accuracy: 0.9312 - val_loss: 1.1890 - val_accuracy: 0.3250\nEpoch 92/100\n5/5 [==============================] - 0s 16ms/step - loss: 0.2981 - accuracy: 0.9250 - val_loss: 1.1925 - val_accuracy: 0.4000\nEpoch 93/100\n5/5 [==============================] - 0s 19ms/step - loss: 0.2900 - accuracy: 0.9250 - val_loss: 1.1805 - val_accuracy: 0.4500\nEpoch 94/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.2811 - accuracy: 0.9187 - val_loss: 1.2043 - val_accuracy: 0.4250\nEpoch 95/100\n5/5 [==============================] - 0s 18ms/step - loss: 0.2755 - accuracy: 0.9500 - val_loss: 1.2527 - val_accuracy: 0.5000\nEpoch 96/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.2685 - accuracy: 0.9688 - val_loss: 1.2422 - val_accuracy: 0.4250\nEpoch 97/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.2666 - accuracy: 0.9500 - val_loss: 1.2357 - val_accuracy: 0.4250\nEpoch 98/100\n5/5 [==============================] - 0s 14ms/step - loss: 0.2627 - accuracy: 0.9187 - val_loss: 1.2669 - val_accuracy: 0.4000\nEpoch 99/100\n5/5 [==============================] - 0s 15ms/step - loss: 0.2991 - accuracy: 0.9125 - val_loss: 1.3108 - val_accuracy: 0.3750\nEpoch 100/100\n5/5 [==============================] - 0s 17ms/step - loss: 0.2727 - accuracy: 0.9375 - val_loss: 1.3253 - val_accuracy: 0.3500\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f9fde08c1c0>"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "model.fit(x=X_train, y=Y_train, epochs=100, validation_data=(X_test, Y_test)) #was 100 but changed to 80 because it's the first time it hit accuracy 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        loss  accuracy  val_loss  val_accuracy\n0   1.320969  0.382812  1.291417      0.320312\n1   1.206415  0.601562  1.219546      0.445312\n2   1.097588  0.712891  1.148925      0.492188\n3   0.999437  0.769531  1.083905      0.523438\n4   0.909609  0.761719  1.039993      0.578125\n..       ...       ...       ...           ...\n95  0.002453  1.000000  1.510520      0.656250\n96  0.002510  1.000000  1.621381      0.648438\n97  0.004113  0.998047  1.610013      0.664062\n98  0.003761  1.000000  1.643598      0.648438\n99  0.001399  1.000000  1.598165      0.671875\n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>accuracy</th>\n      <th>val_loss</th>\n      <th>val_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.320969</td>\n      <td>0.382812</td>\n      <td>1.291417</td>\n      <td>0.320312</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.206415</td>\n      <td>0.601562</td>\n      <td>1.219546</td>\n      <td>0.445312</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.097588</td>\n      <td>0.712891</td>\n      <td>1.148925</td>\n      <td>0.492188</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.999437</td>\n      <td>0.769531</td>\n      <td>1.083905</td>\n      <td>0.523438</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.909609</td>\n      <td>0.761719</td>\n      <td>1.039993</td>\n      <td>0.578125</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.002453</td>\n      <td>1.000000</td>\n      <td>1.510520</td>\n      <td>0.656250</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.002510</td>\n      <td>1.000000</td>\n      <td>1.621381</td>\n      <td>0.648438</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.004113</td>\n      <td>0.998047</td>\n      <td>1.610013</td>\n      <td>0.664062</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.003761</td>\n      <td>1.000000</td>\n      <td>1.643598</td>\n      <td>0.648438</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.001399</td>\n      <td>1.000000</td>\n      <td>1.598165</td>\n      <td>0.671875</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "loss_acc_df = pd.DataFrame(model.history.history)\n",
    "loss_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "metadata": {},
     "execution_count": 103
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-09-19T22:40:40.348580</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m3acbcb8353\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m3acbcb8353\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(48.502557 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.17141\" xlink:href=\"#m3acbcb8353\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g transform=\"translate(106.80891 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.659013\" xlink:href=\"#m3acbcb8353\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g transform=\"translate(168.296513 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"236.146617\" xlink:href=\"#m3acbcb8353\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g transform=\"translate(229.784117 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"297.63422\" xlink:href=\"#m3acbcb8353\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g transform=\"translate(291.27172 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.121823\" xlink:href=\"#m3acbcb8353\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g transform=\"translate(349.578073 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mc05a320ad8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mc05a320ad8\" y=\"214.924775\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.00 -->\n      <g transform=\"translate(7.2 218.723993)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mc05a320ad8\" y=\"184.832078\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.25 -->\n      <g transform=\"translate(7.2 188.631296)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mc05a320ad8\" y=\"154.739381\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.50 -->\n      <g transform=\"translate(7.2 158.538599)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mc05a320ad8\" y=\"124.646684\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.75 -->\n      <g transform=\"translate(7.2 128.445903)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mc05a320ad8\" y=\"94.553987\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.00 -->\n      <g transform=\"translate(7.2 98.353206)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mc05a320ad8\" y=\"64.46129\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.25 -->\n      <g transform=\"translate(7.2 68.260509)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mc05a320ad8\" y=\"34.368593\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.50 -->\n      <g transform=\"translate(7.2 38.167812)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p3823555463)\" d=\"M 51.683807 55.918668 \nL 54.758187 69.707615 \nL 57.832567 82.807249 \nL 60.906947 94.621802 \nL 63.981327 105.434413 \nL 67.055708 114.936459 \nL 70.130088 123.459177 \nL 73.204468 130.548249 \nL 76.278848 137.233603 \nL 79.353228 143.307281 \nL 82.427608 148.822856 \nL 85.501989 153.174738 \nL 88.576369 157.554397 \nL 91.650749 161.007779 \nL 94.725129 164.631035 \nL 97.799509 167.144662 \nL 100.873889 170.29838 \nL 103.94827 173.776296 \nL 107.02265 175.744882 \nL 110.09703 179.132067 \nL 113.17141 181.444158 \nL 116.24579 182.770436 \nL 119.32017 185.140405 \nL 122.394551 186.739227 \nL 125.468931 188.937019 \nL 128.543311 189.824576 \nL 131.617691 190.389182 \nL 134.692071 191.789988 \nL 137.766451 190.507799 \nL 140.840832 195.179725 \nL 143.915212 195.54391 \nL 146.989592 196.745936 \nL 150.063972 198.95268 \nL 153.138352 200.851466 \nL 156.212732 200.023768 \nL 159.287113 200.696688 \nL 162.361493 202.736744 \nL 165.435873 203.795877 \nL 168.510253 205.151461 \nL 171.584633 203.887005 \nL 174.659013 204.846731 \nL 177.733394 205.750758 \nL 180.807774 206.758507 \nL 183.882154 207.407312 \nL 186.956534 208.240023 \nL 190.030914 208.610138 \nL 193.105294 207.247638 \nL 196.179675 206.825502 \nL 199.254055 207.747662 \nL 202.328435 209.918593 \nL 205.402815 210.52568 \nL 208.477195 211.675929 \nL 211.551575 209.646664 \nL 214.625956 210.873794 \nL 217.700336 211.803027 \nL 220.774716 211.471371 \nL 223.849096 212.598127 \nL 226.923476 212.445664 \nL 229.997856 212.172441 \nL 233.072237 211.884552 \nL 236.146617 211.014834 \nL 239.220997 212.651204 \nL 242.295377 212.274669 \nL 245.369757 213.067792 \nL 248.444137 213.286533 \nL 251.518518 212.997133 \nL 254.592898 213.559344 \nL 257.667278 213.346144 \nL 260.741658 213.070366 \nL 263.816038 211.51503 \nL 266.890418 212.010255 \nL 269.964799 212.381913 \nL 273.039179 211.241429 \nL 276.113559 212.72024 \nL 279.187939 213.681283 \nL 282.262319 214.017852 \nL 285.336699 214.1299 \nL 288.41108 214.257132 \nL 291.48546 214.197943 \nL 294.55984 214.142054 \nL 297.63422 214.265076 \nL 300.7086 214.388048 \nL 303.78298 213.827767 \nL 306.857361 214.138834 \nL 309.931741 214.468869 \nL 313.006121 213.931829 \nL 316.080501 213.834861 \nL 319.154881 214.189497 \nL 322.229261 213.803955 \nL 325.303642 214.410417 \nL 328.378022 214.034745 \nL 331.452402 213.711969 \nL 334.526782 214.644123 \nL 337.601162 214.48736 \nL 340.675542 214.554968 \nL 343.749923 214.629492 \nL 346.824303 214.622668 \nL 349.898683 214.429678 \nL 352.973063 214.472065 \nL 356.047443 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p3823555463)\" d=\"M 51.683807 168.845332 \nL 54.758187 142.514223 \nL 57.832567 129.113569 \nL 60.906947 122.295692 \nL 63.981327 123.236089 \nL 67.055708 121.825493 \nL 70.130088 118.769204 \nL 73.204468 117.593708 \nL 76.278848 115.948014 \nL 79.353228 116.418212 \nL 82.427608 114.06722 \nL 85.501989 112.421526 \nL 88.576369 111.24603 \nL 91.650749 112.421526 \nL 94.725129 109.835435 \nL 97.799509 108.18974 \nL 100.873889 107.014244 \nL 103.94827 104.663252 \nL 107.02265 106.073847 \nL 110.09703 102.547359 \nL 113.17141 104.193054 \nL 116.24579 103.252657 \nL 119.32017 101.606963 \nL 122.394551 101.842062 \nL 125.468931 102.077161 \nL 128.543311 100.431467 \nL 131.617691 101.842062 \nL 134.692071 100.666566 \nL 137.766451 102.782459 \nL 140.840832 98.315574 \nL 143.915212 99.961268 \nL 146.989592 99.255971 \nL 150.063972 98.315574 \nL 153.138352 96.904979 \nL 156.212732 98.785772 \nL 159.287113 97.845376 \nL 162.361493 96.904979 \nL 165.435873 97.845376 \nL 168.510253 95.259284 \nL 171.584633 97.140078 \nL 174.659013 96.43478 \nL 177.733394 96.43478 \nL 180.807774 96.43478 \nL 183.882154 96.199681 \nL 186.956534 95.494384 \nL 190.030914 95.964582 \nL 193.105294 96.66988 \nL 196.179675 96.66988 \nL 199.254055 96.66988 \nL 202.328435 95.494384 \nL 205.402815 95.024185 \nL 208.477195 95.024185 \nL 211.551575 96.43478 \nL 214.625956 95.259284 \nL 217.700336 95.024185 \nL 220.774716 94.789086 \nL 223.849096 94.789086 \nL 226.923476 94.789086 \nL 229.997856 95.024185 \nL 233.072237 95.259284 \nL 236.146617 95.494384 \nL 239.220997 95.024185 \nL 242.295377 95.259284 \nL 245.369757 95.024185 \nL 248.444137 94.789086 \nL 251.518518 95.024185 \nL 254.592898 95.024185 \nL 257.667278 95.024185 \nL 260.741658 95.024185 \nL 263.816038 95.964582 \nL 266.890418 95.494384 \nL 269.964799 95.259284 \nL 273.039179 96.43478 \nL 276.113559 95.024185 \nL 279.187939 95.024185 \nL 282.262319 94.553987 \nL 285.336699 94.553987 \nL 288.41108 94.553987 \nL 291.48546 94.789086 \nL 294.55984 94.553987 \nL 297.63422 94.553987 \nL 300.7086 94.553987 \nL 303.78298 95.024185 \nL 306.857361 94.789086 \nL 309.931741 94.553987 \nL 313.006121 94.789086 \nL 316.080501 94.553987 \nL 319.154881 94.553987 \nL 322.229261 95.024185 \nL 325.303642 94.553987 \nL 328.378022 94.789086 \nL 331.452402 95.024185 \nL 334.526782 94.553987 \nL 337.601162 94.553987 \nL 340.675542 94.553987 \nL 343.749923 94.553987 \nL 346.824303 94.553987 \nL 349.898683 94.789086 \nL 352.973063 94.553987 \nL 356.047443 94.553987 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p3823555463)\" d=\"M 51.683807 59.475878 \nL 54.758187 68.127052 \nL 57.832567 76.627759 \nL 60.906947 84.454264 \nL 63.981327 89.740035 \nL 67.055708 96.675878 \nL 70.130088 99.845634 \nL 73.204468 105.2316 \nL 76.278848 109.562267 \nL 79.353228 112.992227 \nL 82.427608 113.884546 \nL 85.501989 118.271512 \nL 88.576369 114.45854 \nL 91.650749 117.156384 \nL 94.725129 119.095672 \nL 97.799509 120.23061 \nL 100.873889 121.863749 \nL 103.94827 123.601286 \nL 107.02265 123.02506 \nL 110.09703 124.471005 \nL 113.17141 125.919109 \nL 116.24579 124.871416 \nL 119.32017 122.153655 \nL 122.394551 122.770496 \nL 125.468931 121.283448 \nL 128.543311 114.973186 \nL 131.617691 117.726827 \nL 134.692071 117.425548 \nL 137.766451 120.671608 \nL 140.840832 119.156786 \nL 143.915212 117.787065 \nL 146.989592 119.830235 \nL 150.063972 117.468525 \nL 153.138352 112.187137 \nL 156.212732 110.361093 \nL 159.287113 116.919613 \nL 162.361493 105.916156 \nL 165.435873 116.624031 \nL 168.510253 113.175238 \nL 171.584633 117.544569 \nL 174.659013 106.985058 \nL 177.733394 115.709054 \nL 180.807774 109.028149 \nL 183.882154 114.145969 \nL 186.956534 107.853873 \nL 190.030914 104.078066 \nL 193.105294 108.295509 \nL 196.179675 102.636906 \nL 199.254055 106.197409 \nL 202.328435 106.490465 \nL 205.402815 96.143705 \nL 208.477195 95.532818 \nL 211.551575 86.823235 \nL 214.625956 99.057398 \nL 217.700336 93.928945 \nL 220.774716 94.072323 \nL 223.849096 86.516103 \nL 226.923476 86.859453 \nL 229.997856 89.902111 \nL 233.072237 79.121828 \nL 236.146617 81.05768 \nL 239.220997 64.781394 \nL 242.295377 81.552272 \nL 245.369757 84.532597 \nL 248.444137 76.883148 \nL 251.518518 78.852377 \nL 254.592898 80.418662 \nL 257.667278 75.768121 \nL 260.741658 62.585892 \nL 263.816038 59.044839 \nL 266.890418 58.758054 \nL 269.964799 59.855432 \nL 273.039179 59.213774 \nL 276.113559 75.805142 \nL 279.187939 63.02214 \nL 282.262319 66.764039 \nL 285.336699 64.153612 \nL 288.41108 65.146814 \nL 291.48546 63.424466 \nL 294.55984 58.483996 \nL 297.63422 61.071551 \nL 300.7086 59.694849 \nL 303.78298 63.478835 \nL 306.857361 52.777072 \nL 309.931741 64.046695 \nL 313.006121 55.327563 \nL 316.080501 58.166073 \nL 319.154881 48.957126 \nL 322.229261 38.244802 \nL 325.303642 37.399312 \nL 328.378022 35.173762 \nL 331.452402 38.694252 \nL 334.526782 34.924285 \nL 337.601162 38.390649 \nL 340.675542 36.8906 \nL 343.749923 33.10228 \nL 346.824303 19.757847 \nL 349.898683 21.126298 \nL 352.973063 17.083636 \nL 356.047443 22.552376 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p3823555463)\" d=\"M 51.683807 176.368507 \nL 54.758187 161.322158 \nL 57.832567 155.679778 \nL 60.906947 151.91819 \nL 63.981327 145.335413 \nL 67.055708 139.693032 \nL 70.130088 149.097 \nL 73.204468 144.395016 \nL 76.278848 139.693032 \nL 79.353228 137.812239 \nL 82.427608 142.514223 \nL 85.501989 136.871842 \nL 88.576369 145.335413 \nL 91.650749 141.573826 \nL 94.725129 136.871842 \nL 97.799509 139.693032 \nL 100.873889 139.693032 \nL 103.94827 140.633429 \nL 107.02265 143.454619 \nL 110.09703 134.050652 \nL 113.17141 135.931445 \nL 116.24579 132.169858 \nL 119.32017 139.693032 \nL 122.394551 140.633429 \nL 125.468931 136.871842 \nL 128.543311 139.693032 \nL 131.617691 136.871842 \nL 134.692071 135.931445 \nL 137.766451 134.050652 \nL 140.840832 139.693032 \nL 143.915212 137.812239 \nL 146.989592 131.229461 \nL 150.063972 134.991048 \nL 153.138352 135.931445 \nL 156.212732 135.931445 \nL 159.287113 134.050652 \nL 162.361493 136.871842 \nL 165.435873 128.408271 \nL 168.510253 131.229461 \nL 171.584633 128.408271 \nL 174.659013 133.110255 \nL 177.733394 128.408271 \nL 180.807774 130.289064 \nL 183.882154 127.467874 \nL 186.956534 130.289064 \nL 190.030914 130.289064 \nL 193.105294 130.289064 \nL 196.179675 129.348668 \nL 199.254055 130.289064 \nL 202.328435 129.348668 \nL 205.402815 132.169858 \nL 208.477195 131.229461 \nL 211.551575 133.110255 \nL 214.625956 126.527477 \nL 217.700336 129.348668 \nL 220.774716 125.587081 \nL 223.849096 130.289064 \nL 226.923476 133.110255 \nL 229.997856 133.110255 \nL 233.072237 133.110255 \nL 236.146617 131.229461 \nL 239.220997 135.931445 \nL 242.295377 130.289064 \nL 245.369757 126.527477 \nL 248.444137 132.169858 \nL 251.518518 129.348668 \nL 254.592898 133.110255 \nL 257.667278 129.348668 \nL 260.741658 134.991048 \nL 263.816038 134.991048 \nL 266.890418 140.633429 \nL 269.964799 134.991048 \nL 273.039179 135.931445 \nL 276.113559 131.229461 \nL 279.187939 132.169858 \nL 282.262319 130.289064 \nL 285.336699 131.229461 \nL 288.41108 129.348668 \nL 291.48546 129.348668 \nL 294.55984 131.229461 \nL 297.63422 126.527477 \nL 300.7086 131.229461 \nL 303.78298 133.110255 \nL 306.857361 132.169858 \nL 309.931741 128.408271 \nL 313.006121 132.169858 \nL 316.080501 128.408271 \nL 319.154881 127.467874 \nL 322.229261 132.169858 \nL 325.303642 133.110255 \nL 328.378022 132.169858 \nL 331.452402 134.050652 \nL 334.526782 131.229461 \nL 337.601162 126.527477 \nL 340.675542 133.110255 \nL 343.749923 135.931445 \nL 346.824303 136.871842 \nL 349.898683 134.991048 \nL 352.973063 136.871842 \nL 356.047443 134.050652 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 155.39375 74.46875 \nL 252.3375 74.46875 \nQ 254.3375 74.46875 254.3375 72.46875 \nL 254.3375 14.2 \nQ 254.3375 12.2 252.3375 12.2 \nL 155.39375 12.2 \nQ 153.39375 12.2 153.39375 14.2 \nL 153.39375 72.46875 \nQ 153.39375 74.46875 155.39375 74.46875 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 157.39375 20.298437 \nL 177.39375 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_14\">\n     <!-- loss -->\n     <g transform=\"translate(185.39375 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 157.39375 34.976562 \nL 177.39375 34.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_15\">\n     <!-- accuracy -->\n     <g transform=\"translate(185.39375 38.476562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 157.39375 49.654687 \nL 177.39375 49.654687 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_23\"/>\n    <g id=\"text_16\">\n     <!-- val_loss -->\n     <g transform=\"translate(185.39375 53.154687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n       <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 157.39375 64.610937 \nL 177.39375 64.610937 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_25\"/>\n    <g id=\"text_17\">\n     <!-- val_accuracy -->\n     <g transform=\"translate(185.39375 68.110937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"259.521484\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"369.482422\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"432.861328\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"473.974609\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"535.253906\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"590.234375\" xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p3823555463\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "loss_acc_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4/4 [==============================] - 0s 2ms/step - loss: 1.1033 - accuracy: 0.5938\n0.59375\n"
    }
   ],
   "source": [
    "print(model.evaluate(X_test, Y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.003 0.003 0.033 0.   ]\n [0.    0.    0.001 0.25 ]\n [0.007 0.028 0.001 0.   ]\n [0.028 0.003 0.001 0.   ]\n [0.02  0.014 0.    0.   ]\n [0.007 0.001 0.012 0.002]\n [0.    0.06  0.001 0.034]\n [0.002 0.009 0.001 0.   ]\n [0.    0.    0.    0.712]\n [0.029 0.011 0.001 0.   ]\n [0.    0.001 0.033 0.   ]\n [0.004 0.002 0.    0.   ]\n [0.    0.134 0.    0.   ]\n [0.002 0.001 0.008 0.   ]\n [0.    0.004 0.011 0.   ]\n [0.053 0.004 0.003 0.   ]\n [0.001 0.007 0.001 0.   ]\n [0.001 0.    0.006 0.   ]\n [0.    0.003 0.001 0.   ]\n [0.001 0.008 0.001 0.   ]\n [0.    0.011 0.032 0.118]\n [0.032 0.    0.    0.   ]\n [0.007 0.01  0.002 0.   ]\n [0.    0.002 0.    0.016]\n [0.    0.001 0.009 0.019]\n [0.007 0.    0.062 0.001]\n [0.    0.002 0.    0.041]\n [0.01  0.002 0.028 0.   ]\n [0.001 0.    0.008 0.   ]\n [0.    0.001 0.001 0.057]\n [0.001 0.118 0.001 0.   ]\n [0.006 0.015 0.    0.   ]\n [0.078 0.    0.008 0.   ]\n [0.014 0.003 0.001 0.   ]\n [0.001 0.    0.022 0.   ]\n [0.003 0.022 0.001 0.   ]\n [0.001 0.009 0.003 0.02 ]\n [0.023 0.021 0.    0.   ]\n [0.    0.002 0.002 0.   ]\n [0.004 0.024 0.001 0.   ]\n [0.02  0.001 0.001 0.   ]\n [0.    0.    0.06  0.001]\n [0.    0.011 0.005 0.016]\n [0.    0.013 0.    0.011]\n [0.001 0.009 0.007 0.   ]\n [0.073 0.001 0.003 0.   ]\n [0.    0.001 0.002 0.01 ]\n [0.02  0.014 0.    0.   ]\n [0.    0.    0.503 0.002]\n [0.    0.001 0.001 0.001]]\n"
    }
   ],
   "source": [
    "print(test_predictions.round(decimals=3)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.],\n       [0., 1., 0., 0.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.],\n       [0., 0., 0., 1.],\n       [0., 0., 1., 0.],\n       [1., 0., 0., 0.],\n       [0., 0., 0., 1.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 1., 0.]])"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "Y_test[:50]"
   ]
  },
  {
   "source": [
    "Getting indexes 0 to 3 of values on marix that have max value to compute tables below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 3, 1, 0, 0, 2, 1, 1, 3, 0])"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "test_predictions_indices = np.argmax(test_predictions, axis=1)\n",
    "test_predictions_indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 3, 1, 0, 1, 1, 3, 0, 3, 0])"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "Y_test_indices = np.argmax(Y_test, axis=1)\n",
    "Y_test_indices[:10]"
   ]
  },
  {
   "source": [
    "Confusion matrix\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[16  8  1  0]\n [14 18  3  0]\n [ 2  6 23  6]\n [ 0  4  8 19]]\n"
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_indices, test_predictions_indices,))"
   ]
  },
  {
   "source": [
    "Model 2 - same as above but using softmax"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Model 3 - Using early stop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,activation='sigmoid'))\n",
    "model.add(Dense(50,activation='sigmoid'))\n",
    "model.add(Dense(4,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5000\n5/5 [==============================] - 0s 67ms/step - loss: 1.4066 - accuracy: 0.2438 - val_loss: 1.3449 - val_accuracy: 0.4000\nEpoch 2/5000\n5/5 [==============================] - 0s 15ms/step - loss: 1.2871 - accuracy: 0.3938 - val_loss: 1.3164 - val_accuracy: 0.4000\nEpoch 3/5000\n5/5 [==============================] - 0s 14ms/step - loss: 1.2228 - accuracy: 0.5562 - val_loss: 1.2879 - val_accuracy: 0.4000\nEpoch 4/5000\n5/5 [==============================] - 0s 16ms/step - loss: 1.1700 - accuracy: 0.6938 - val_loss: 1.2585 - val_accuracy: 0.4000\nEpoch 5/5000\n5/5 [==============================] - 0s 16ms/step - loss: 1.1201 - accuracy: 0.7625 - val_loss: 1.2326 - val_accuracy: 0.4750\nEpoch 6/5000\n5/5 [==============================] - 0s 16ms/step - loss: 1.0730 - accuracy: 0.7750 - val_loss: 1.2058 - val_accuracy: 0.3250\nEpoch 7/5000\n5/5 [==============================] - 0s 14ms/step - loss: 1.0362 - accuracy: 0.7688 - val_loss: 1.1794 - val_accuracy: 0.5250\nEpoch 8/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.9980 - accuracy: 0.7750 - val_loss: 1.1536 - val_accuracy: 0.5500\nEpoch 9/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.9632 - accuracy: 0.7812 - val_loss: 1.1406 - val_accuracy: 0.5250\nEpoch 10/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.9270 - accuracy: 0.8000 - val_loss: 1.1308 - val_accuracy: 0.5250\nEpoch 11/5000\n5/5 [==============================] - 0s 12ms/step - loss: 0.8955 - accuracy: 0.7812 - val_loss: 1.0926 - val_accuracy: 0.6500\nEpoch 12/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.8701 - accuracy: 0.7812 - val_loss: 1.0748 - val_accuracy: 0.6250\nEpoch 13/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.8343 - accuracy: 0.8188 - val_loss: 1.0547 - val_accuracy: 0.6750\nEpoch 14/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.8079 - accuracy: 0.8250 - val_loss: 1.0478 - val_accuracy: 0.6500\nEpoch 15/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.7789 - accuracy: 0.8188 - val_loss: 1.0338 - val_accuracy: 0.6500\nEpoch 16/5000\n5/5 [==============================] - 0s 11ms/step - loss: 0.7590 - accuracy: 0.8375 - val_loss: 1.0137 - val_accuracy: 0.6750\nEpoch 17/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.7317 - accuracy: 0.8375 - val_loss: 0.9900 - val_accuracy: 0.6750\nEpoch 18/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.7081 - accuracy: 0.8313 - val_loss: 0.9844 - val_accuracy: 0.7000\nEpoch 19/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.6833 - accuracy: 0.8625 - val_loss: 0.9703 - val_accuracy: 0.7000\nEpoch 20/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.6619 - accuracy: 0.8188 - val_loss: 0.9497 - val_accuracy: 0.7250\nEpoch 21/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.6441 - accuracy: 0.8562 - val_loss: 0.9426 - val_accuracy: 0.7000\nEpoch 22/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.6226 - accuracy: 0.8562 - val_loss: 0.9515 - val_accuracy: 0.6500\nEpoch 23/5000\n5/5 [==============================] - 0s 21ms/step - loss: 0.6145 - accuracy: 0.8250 - val_loss: 0.9559 - val_accuracy: 0.6500\nEpoch 24/5000\n5/5 [==============================] - 0s 12ms/step - loss: 0.5846 - accuracy: 0.8625 - val_loss: 0.9598 - val_accuracy: 0.6000\nEpoch 25/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.5694 - accuracy: 0.8313 - val_loss: 0.9574 - val_accuracy: 0.5500\nEpoch 26/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.5579 - accuracy: 0.8875 - val_loss: 0.9633 - val_accuracy: 0.5500\nEpoch 27/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.5374 - accuracy: 0.8375 - val_loss: 0.9411 - val_accuracy: 0.5500\nEpoch 28/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.5212 - accuracy: 0.8438 - val_loss: 0.9395 - val_accuracy: 0.5750\nEpoch 29/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.4974 - accuracy: 0.8375 - val_loss: 0.9216 - val_accuracy: 0.6000\nEpoch 30/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.4918 - accuracy: 0.8375 - val_loss: 0.9236 - val_accuracy: 0.5000\nEpoch 31/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.4718 - accuracy: 0.8625 - val_loss: 0.9139 - val_accuracy: 0.5750\nEpoch 32/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.4569 - accuracy: 0.8438 - val_loss: 0.9002 - val_accuracy: 0.5500\nEpoch 33/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.4474 - accuracy: 0.8625 - val_loss: 0.9176 - val_accuracy: 0.5000\nEpoch 34/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.4376 - accuracy: 0.8750 - val_loss: 0.8903 - val_accuracy: 0.5500\nEpoch 35/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.4250 - accuracy: 0.8687 - val_loss: 0.8875 - val_accuracy: 0.6250\nEpoch 36/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.4090 - accuracy: 0.8625 - val_loss: 0.8933 - val_accuracy: 0.5250\nEpoch 37/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.4000 - accuracy: 0.8687 - val_loss: 0.8933 - val_accuracy: 0.5250\nEpoch 38/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.3902 - accuracy: 0.8562 - val_loss: 0.9123 - val_accuracy: 0.5000\nEpoch 39/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.3788 - accuracy: 0.8938 - val_loss: 0.8920 - val_accuracy: 0.5750\nEpoch 40/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.3786 - accuracy: 0.8625 - val_loss: 0.8980 - val_accuracy: 0.5250\nEpoch 41/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.3653 - accuracy: 0.8625 - val_loss: 0.8892 - val_accuracy: 0.6000\nEpoch 42/5000\n5/5 [==============================] - 0s 22ms/step - loss: 0.3567 - accuracy: 0.8813 - val_loss: 0.8667 - val_accuracy: 0.5500\nEpoch 43/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.3550 - accuracy: 0.8687 - val_loss: 0.8746 - val_accuracy: 0.5500\nEpoch 44/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.3494 - accuracy: 0.8750 - val_loss: 0.8948 - val_accuracy: 0.5750\nEpoch 45/5000\n5/5 [==============================] - 0s 21ms/step - loss: 0.3376 - accuracy: 0.8687 - val_loss: 0.8767 - val_accuracy: 0.5750\nEpoch 46/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.3370 - accuracy: 0.8687 - val_loss: 0.8908 - val_accuracy: 0.5750\nEpoch 47/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.3319 - accuracy: 0.8687 - val_loss: 0.8927 - val_accuracy: 0.5750\nEpoch 48/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.3365 - accuracy: 0.8562 - val_loss: 0.8920 - val_accuracy: 0.5500\nEpoch 49/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.3193 - accuracy: 0.8687 - val_loss: 0.8847 - val_accuracy: 0.5500\nEpoch 50/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.3131 - accuracy: 0.8875 - val_loss: 0.8896 - val_accuracy: 0.5000\nEpoch 51/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.3091 - accuracy: 0.8750 - val_loss: 0.9124 - val_accuracy: 0.4750\nEpoch 52/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.3115 - accuracy: 0.8625 - val_loss: 0.9230 - val_accuracy: 0.4750\nEpoch 53/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.3164 - accuracy: 0.8500 - val_loss: 0.9251 - val_accuracy: 0.4750\nEpoch 54/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.2988 - accuracy: 0.8625 - val_loss: 0.9271 - val_accuracy: 0.5000\nEpoch 55/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.2970 - accuracy: 0.8625 - val_loss: 0.9149 - val_accuracy: 0.5250\nEpoch 56/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.3028 - accuracy: 0.8750 - val_loss: 0.9088 - val_accuracy: 0.5250\nEpoch 57/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.2844 - accuracy: 0.8813 - val_loss: 0.9378 - val_accuracy: 0.5000\nEpoch 58/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.2778 - accuracy: 0.9187 - val_loss: 0.9245 - val_accuracy: 0.4750\nEpoch 59/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.2747 - accuracy: 0.8813 - val_loss: 0.9355 - val_accuracy: 0.5000\nEpoch 60/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.2742 - accuracy: 0.9062 - val_loss: 0.9230 - val_accuracy: 0.5500\nEpoch 61/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.2742 - accuracy: 0.8750 - val_loss: 0.9363 - val_accuracy: 0.4500\nEpoch 62/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.2693 - accuracy: 0.8938 - val_loss: 0.9021 - val_accuracy: 0.4750\nEpoch 63/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.2725 - accuracy: 0.8750 - val_loss: 0.9282 - val_accuracy: 0.5750\nEpoch 64/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.2646 - accuracy: 0.8938 - val_loss: 0.9200 - val_accuracy: 0.4750\nEpoch 65/5000\n5/5 [==============================] - 0s 11ms/step - loss: 0.2634 - accuracy: 0.8875 - val_loss: 0.9309 - val_accuracy: 0.5250\nEpoch 66/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.2613 - accuracy: 0.9062 - val_loss: 0.9291 - val_accuracy: 0.4750\nEpoch 67/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.2611 - accuracy: 0.8687 - val_loss: 0.9509 - val_accuracy: 0.5250\nEpoch 68/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.2527 - accuracy: 0.9000 - val_loss: 0.9503 - val_accuracy: 0.5000\nEpoch 69/5000\n5/5 [==============================] - 0s 19ms/step - loss: 0.2585 - accuracy: 0.8875 - val_loss: 0.9784 - val_accuracy: 0.5250\nEpoch 70/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.2556 - accuracy: 0.8938 - val_loss: 0.9633 - val_accuracy: 0.5000\nEpoch 71/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.2489 - accuracy: 0.8875 - val_loss: 0.9812 - val_accuracy: 0.5250\nEpoch 72/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.2431 - accuracy: 0.8875 - val_loss: 0.9502 - val_accuracy: 0.5000\nEpoch 73/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.2434 - accuracy: 0.8875 - val_loss: 0.9436 - val_accuracy: 0.5000\nEpoch 74/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.2417 - accuracy: 0.9000 - val_loss: 0.9801 - val_accuracy: 0.5000\nEpoch 75/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.2409 - accuracy: 0.8938 - val_loss: 1.0032 - val_accuracy: 0.4500\nEpoch 76/5000\n5/5 [==============================] - 0s 22ms/step - loss: 0.2405 - accuracy: 0.9000 - val_loss: 1.0012 - val_accuracy: 0.5000\nEpoch 77/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.2405 - accuracy: 0.9000 - val_loss: 0.9960 - val_accuracy: 0.4500\nEpoch 78/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.2364 - accuracy: 0.8875 - val_loss: 1.0037 - val_accuracy: 0.4500\nEpoch 79/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.2356 - accuracy: 0.8813 - val_loss: 1.0130 - val_accuracy: 0.4500\nEpoch 80/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.2399 - accuracy: 0.8938 - val_loss: 1.0057 - val_accuracy: 0.4500\nEpoch 81/5000\n5/5 [==============================] - 0s 19ms/step - loss: 0.2339 - accuracy: 0.8875 - val_loss: 1.0323 - val_accuracy: 0.4750\nEpoch 82/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.2308 - accuracy: 0.9000 - val_loss: 1.0147 - val_accuracy: 0.4750\nEpoch 83/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.2341 - accuracy: 0.8813 - val_loss: 1.0164 - val_accuracy: 0.5000\nEpoch 84/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.2312 - accuracy: 0.8813 - val_loss: 1.0596 - val_accuracy: 0.4000\nEpoch 85/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.2379 - accuracy: 0.8750 - val_loss: 1.0317 - val_accuracy: 0.4500\nEpoch 86/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.2266 - accuracy: 0.9125 - val_loss: 1.0171 - val_accuracy: 0.5000\nEpoch 87/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.2231 - accuracy: 0.9062 - val_loss: 1.0178 - val_accuracy: 0.5000\nEpoch 88/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.2253 - accuracy: 0.8813 - val_loss: 1.0286 - val_accuracy: 0.5000\nEpoch 89/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.2124 - accuracy: 0.9000 - val_loss: 1.0516 - val_accuracy: 0.4750\nEpoch 90/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.2278 - accuracy: 0.8750 - val_loss: 1.0438 - val_accuracy: 0.5000\nEpoch 91/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.2207 - accuracy: 0.8813 - val_loss: 1.0085 - val_accuracy: 0.5250\nEpoch 92/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.2275 - accuracy: 0.8687 - val_loss: 1.0310 - val_accuracy: 0.5250\nEpoch 93/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.2179 - accuracy: 0.8938 - val_loss: 1.0829 - val_accuracy: 0.5500\nEpoch 94/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 0.9000 - val_loss: 1.0998 - val_accuracy: 0.5250\nEpoch 95/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.1946 - accuracy: 0.9000 - val_loss: 1.1032 - val_accuracy: 0.5000\nEpoch 96/5000\n5/5 [==============================] - 0s 19ms/step - loss: 0.2051 - accuracy: 0.9000 - val_loss: 1.0992 - val_accuracy: 0.5000\nEpoch 97/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.2294 - accuracy: 0.8750 - val_loss: 1.0837 - val_accuracy: 0.5500\nEpoch 98/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.1889 - accuracy: 0.9125 - val_loss: 1.0638 - val_accuracy: 0.5500\nEpoch 99/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.2126 - accuracy: 0.8750 - val_loss: 1.0525 - val_accuracy: 0.6500\nEpoch 100/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.1906 - accuracy: 0.9125 - val_loss: 1.0054 - val_accuracy: 0.5500\nEpoch 101/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.1838 - accuracy: 0.9250 - val_loss: 1.0111 - val_accuracy: 0.5500\nEpoch 102/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.1848 - accuracy: 0.9062 - val_loss: 1.0291 - val_accuracy: 0.5500\nEpoch 103/5000\n5/5 [==============================] - 0s 12ms/step - loss: 0.1849 - accuracy: 0.9125 - val_loss: 1.0463 - val_accuracy: 0.6000\nEpoch 104/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.1853 - accuracy: 0.9250 - val_loss: 1.0396 - val_accuracy: 0.5750\nEpoch 105/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.1823 - accuracy: 0.9187 - val_loss: 1.0672 - val_accuracy: 0.5750\nEpoch 106/5000\n5/5 [==============================] - 0s 14ms/step - loss: 0.1811 - accuracy: 0.9250 - val_loss: 1.0758 - val_accuracy: 0.5750\nEpoch 107/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.1808 - accuracy: 0.9187 - val_loss: 1.1162 - val_accuracy: 0.5500\nEpoch 108/5000\n5/5 [==============================] - 0s 18ms/step - loss: 0.1898 - accuracy: 0.9187 - val_loss: 1.1162 - val_accuracy: 0.5750\nEpoch 109/5000\n5/5 [==============================] - 0s 20ms/step - loss: 0.1838 - accuracy: 0.9250 - val_loss: 1.1320 - val_accuracy: 0.5500\nEpoch 110/5000\n5/5 [==============================] - 0s 22ms/step - loss: 0.1838 - accuracy: 0.9312 - val_loss: 1.1109 - val_accuracy: 0.6000\nEpoch 111/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.1946 - accuracy: 0.9000 - val_loss: 1.1649 - val_accuracy: 0.5250\nEpoch 112/5000\n5/5 [==============================] - 0s 17ms/step - loss: 0.1875 - accuracy: 0.9062 - val_loss: 1.2015 - val_accuracy: 0.5500\nEpoch 113/5000\n5/5 [==============================] - 0s 19ms/step - loss: 0.1890 - accuracy: 0.9000 - val_loss: 1.1633 - val_accuracy: 0.5500\nEpoch 114/5000\n5/5 [==============================] - 0s 15ms/step - loss: 0.1903 - accuracy: 0.9062 - val_loss: 1.2037 - val_accuracy: 0.5250\nEpoch 115/5000\n5/5 [==============================] - 0s 16ms/step - loss: 0.1806 - accuracy: 0.9125 - val_loss: 1.2097 - val_accuracy: 0.5250\nEpoch 116/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.1864 - accuracy: 0.9062 - val_loss: 1.2330 - val_accuracy: 0.5000\nEpoch 117/5000\n5/5 [==============================] - 0s 19ms/step - loss: 0.1892 - accuracy: 0.9125 - val_loss: 1.2463 - val_accuracy: 0.5000\nEpoch 118/5000\n5/5 [==============================] - 0s 21ms/step - loss: 0.1861 - accuracy: 0.9312 - val_loss: 1.2321 - val_accuracy: 0.5000\nEpoch 119/5000\n5/5 [==============================] - 0s 13ms/step - loss: 0.1838 - accuracy: 0.9187 - val_loss: 1.2063 - val_accuracy: 0.5750\nEpoch 120/5000\n5/5 [==============================] - 0s 21ms/step - loss: 0.1852 - accuracy: 0.9312 - val_loss: 1.2131 - val_accuracy: 0.5500\nEpoch 00120: early stopping\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f9fddd1bf10>"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "model.fit(x=X_train, y=Y_train, epochs=5000, validation_data=(X_test,Y_test), callbacks=[early_stop])"
   ]
  },
  {
   "source": [
    "Model 4 - using early stop and dropouts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50,activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==============] - 0s 7ms/step - loss: 0.3516 - accuracy: 0.8340 - val_loss: 0.7271 - val_accuracy: 0.6797\nEpoch 93/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8594 - val_loss: 0.7378 - val_accuracy: 0.6641\nEpoch 94/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.3010 - accuracy: 0.8828 - val_loss: 0.7276 - val_accuracy: 0.6562\nEpoch 95/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.3299 - accuracy: 0.8496 - val_loss: 0.7597 - val_accuracy: 0.6797\nEpoch 96/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8477 - val_loss: 0.7514 - val_accuracy: 0.6641\nEpoch 97/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2798 - accuracy: 0.8730 - val_loss: 0.7276 - val_accuracy: 0.6562\nEpoch 98/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.3260 - accuracy: 0.8535 - val_loss: 0.7360 - val_accuracy: 0.6953\nEpoch 99/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8828 - val_loss: 0.7539 - val_accuracy: 0.6562\nEpoch 100/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.8398 - val_loss: 0.7356 - val_accuracy: 0.6719\nEpoch 101/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2978 - accuracy: 0.8574 - val_loss: 0.7356 - val_accuracy: 0.7188\nEpoch 102/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2958 - accuracy: 0.8750 - val_loss: 0.7240 - val_accuracy: 0.7266\nEpoch 103/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.2884 - accuracy: 0.8867 - val_loss: 0.7250 - val_accuracy: 0.7344\nEpoch 104/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2782 - accuracy: 0.9004 - val_loss: 0.7780 - val_accuracy: 0.6797\nEpoch 105/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8672 - val_loss: 0.7780 - val_accuracy: 0.7188\nEpoch 106/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.3064 - accuracy: 0.8711 - val_loss: 0.7274 - val_accuracy: 0.7188\nEpoch 107/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2617 - accuracy: 0.8789 - val_loss: 0.7641 - val_accuracy: 0.6797\nEpoch 108/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8594 - val_loss: 0.7874 - val_accuracy: 0.6641\nEpoch 109/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.3125 - accuracy: 0.8652 - val_loss: 0.8037 - val_accuracy: 0.6562\nEpoch 110/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.3001 - accuracy: 0.8906 - val_loss: 0.8084 - val_accuracy: 0.6250\nEpoch 111/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2631 - accuracy: 0.8828 - val_loss: 0.7797 - val_accuracy: 0.6719\nEpoch 112/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2785 - accuracy: 0.8711 - val_loss: 0.8248 - val_accuracy: 0.6328\nEpoch 113/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2534 - accuracy: 0.9082 - val_loss: 0.8041 - val_accuracy: 0.6484\nEpoch 114/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.2753 - accuracy: 0.8945 - val_loss: 0.8020 - val_accuracy: 0.6641\nEpoch 115/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2419 - accuracy: 0.9004 - val_loss: 0.8005 - val_accuracy: 0.6953\nEpoch 116/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2729 - accuracy: 0.8906 - val_loss: 0.8061 - val_accuracy: 0.6953\nEpoch 117/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.8828 - val_loss: 0.7747 - val_accuracy: 0.7109\nEpoch 118/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.9023 - val_loss: 0.7439 - val_accuracy: 0.7109\nEpoch 119/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.2427 - accuracy: 0.9160 - val_loss: 0.7754 - val_accuracy: 0.6953\nEpoch 120/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2464 - accuracy: 0.9062 - val_loss: 0.8016 - val_accuracy: 0.7031\nEpoch 121/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2483 - accuracy: 0.9023 - val_loss: 0.7995 - val_accuracy: 0.7109\nEpoch 122/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2195 - accuracy: 0.9121 - val_loss: 0.8427 - val_accuracy: 0.6797\nEpoch 123/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2444 - accuracy: 0.9023 - val_loss: 0.8123 - val_accuracy: 0.6797\nEpoch 124/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2388 - accuracy: 0.9082 - val_loss: 0.8603 - val_accuracy: 0.6953\nEpoch 125/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.2428 - accuracy: 0.9102 - val_loss: 0.8678 - val_accuracy: 0.6953\nEpoch 126/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.2123 - accuracy: 0.9180 - val_loss: 0.8495 - val_accuracy: 0.6797\nEpoch 127/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2323 - accuracy: 0.9121 - val_loss: 0.8721 - val_accuracy: 0.6797\nEpoch 128/5000\n16/16 [==============================] - 0s 10ms/step - loss: 0.2326 - accuracy: 0.9062 - val_loss: 0.8420 - val_accuracy: 0.7031\nEpoch 129/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2121 - accuracy: 0.9102 - val_loss: 0.8383 - val_accuracy: 0.7188\nEpoch 130/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2010 - accuracy: 0.9180 - val_loss: 0.8009 - val_accuracy: 0.7422\nEpoch 131/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2071 - accuracy: 0.9238 - val_loss: 0.8033 - val_accuracy: 0.7266\nEpoch 132/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1900 - accuracy: 0.9160 - val_loss: 0.8291 - val_accuracy: 0.7266\nEpoch 133/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2329 - accuracy: 0.9004 - val_loss: 0.8348 - val_accuracy: 0.6875\nEpoch 134/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2047 - accuracy: 0.9199 - val_loss: 0.8713 - val_accuracy: 0.6797\nEpoch 135/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1958 - accuracy: 0.9238 - val_loss: 0.8046 - val_accuracy: 0.7344\nEpoch 136/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1733 - accuracy: 0.9199 - val_loss: 0.8976 - val_accuracy: 0.7031\nEpoch 137/5000\n16/16 [==============================] - 0s 9ms/step - loss: 0.2156 - accuracy: 0.9082 - val_loss: 0.8774 - val_accuracy: 0.7031\nEpoch 138/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.2201 - accuracy: 0.9102 - val_loss: 0.8939 - val_accuracy: 0.7031\nEpoch 139/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2064 - accuracy: 0.9141 - val_loss: 0.8902 - val_accuracy: 0.6875\nEpoch 140/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2199 - accuracy: 0.9160 - val_loss: 0.8585 - val_accuracy: 0.7031\nEpoch 141/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2049 - accuracy: 0.9102 - val_loss: 0.8663 - val_accuracy: 0.7031\nEpoch 142/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.2159 - accuracy: 0.9102 - val_loss: 0.8910 - val_accuracy: 0.6953\nEpoch 143/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1947 - accuracy: 0.9297 - val_loss: 0.9257 - val_accuracy: 0.7031\nEpoch 144/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.2661 - accuracy: 0.9043 - val_loss: 0.9036 - val_accuracy: 0.6797\nEpoch 145/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2404 - accuracy: 0.9062 - val_loss: 0.9625 - val_accuracy: 0.6641\nEpoch 146/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2233 - accuracy: 0.9043 - val_loss: 0.9042 - val_accuracy: 0.6797\nEpoch 147/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2242 - accuracy: 0.9102 - val_loss: 0.9353 - val_accuracy: 0.7031\nEpoch 148/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2026 - accuracy: 0.9199 - val_loss: 0.9330 - val_accuracy: 0.6875\nEpoch 149/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1816 - accuracy: 0.9395 - val_loss: 0.9198 - val_accuracy: 0.7031\nEpoch 150/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2109 - accuracy: 0.9297 - val_loss: 0.8733 - val_accuracy: 0.7266\nEpoch 151/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1752 - accuracy: 0.9336 - val_loss: 0.9807 - val_accuracy: 0.6406\nEpoch 152/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2003 - accuracy: 0.9219 - val_loss: 0.9494 - val_accuracy: 0.7109\nEpoch 153/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1899 - accuracy: 0.9258 - val_loss: 0.9980 - val_accuracy: 0.6641\nEpoch 154/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2015 - accuracy: 0.9199 - val_loss: 1.0013 - val_accuracy: 0.6406\nEpoch 155/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1855 - accuracy: 0.9199 - val_loss: 0.9762 - val_accuracy: 0.6719\nEpoch 156/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1711 - accuracy: 0.9297 - val_loss: 0.9315 - val_accuracy: 0.6953\nEpoch 157/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2383 - accuracy: 0.9023 - val_loss: 0.9955 - val_accuracy: 0.6719\nEpoch 158/5000\n16/16 [==============================] - 0s 9ms/step - loss: 0.2438 - accuracy: 0.9023 - val_loss: 0.9325 - val_accuracy: 0.6875\nEpoch 159/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.2510 - accuracy: 0.9082 - val_loss: 0.9796 - val_accuracy: 0.6875\nEpoch 160/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2953 - accuracy: 0.8867 - val_loss: 0.9583 - val_accuracy: 0.7188\nEpoch 161/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2403 - accuracy: 0.9121 - val_loss: 0.9934 - val_accuracy: 0.6875\nEpoch 162/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2090 - accuracy: 0.9277 - val_loss: 0.9654 - val_accuracy: 0.6719\nEpoch 163/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2184 - accuracy: 0.9082 - val_loss: 0.9938 - val_accuracy: 0.7031\nEpoch 164/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.2082 - accuracy: 0.9180 - val_loss: 0.9807 - val_accuracy: 0.7188\nEpoch 165/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2412 - accuracy: 0.9043 - val_loss: 0.9981 - val_accuracy: 0.6797\nEpoch 166/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.2113 - accuracy: 0.9121 - val_loss: 0.9798 - val_accuracy: 0.7031\nEpoch 167/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1975 - accuracy: 0.9199 - val_loss: 0.9586 - val_accuracy: 0.7109\nEpoch 168/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1818 - accuracy: 0.9219 - val_loss: 0.9509 - val_accuracy: 0.6953\nEpoch 169/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.1752 - accuracy: 0.9316 - val_loss: 0.9441 - val_accuracy: 0.7344\nEpoch 170/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1651 - accuracy: 0.9395 - val_loss: 1.0196 - val_accuracy: 0.6641\nEpoch 171/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1624 - accuracy: 0.9434 - val_loss: 0.9541 - val_accuracy: 0.7109\nEpoch 172/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1703 - accuracy: 0.9395 - val_loss: 0.9388 - val_accuracy: 0.6953\nEpoch 173/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1841 - accuracy: 0.9316 - val_loss: 0.9392 - val_accuracy: 0.7109\nEpoch 174/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1623 - accuracy: 0.9375 - val_loss: 0.9972 - val_accuracy: 0.7031\nEpoch 175/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1692 - accuracy: 0.9316 - val_loss: 1.0034 - val_accuracy: 0.7031\nEpoch 176/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1648 - accuracy: 0.9355 - val_loss: 0.9753 - val_accuracy: 0.7031\nEpoch 177/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1498 - accuracy: 0.9434 - val_loss: 0.9794 - val_accuracy: 0.7031\nEpoch 178/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1503 - accuracy: 0.9453 - val_loss: 0.9942 - val_accuracy: 0.6953\nEpoch 179/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.1373 - accuracy: 0.9434 - val_loss: 1.0165 - val_accuracy: 0.7109\nEpoch 180/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1687 - accuracy: 0.9336 - val_loss: 0.9641 - val_accuracy: 0.7188\nEpoch 181/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1850 - accuracy: 0.9258 - val_loss: 1.0281 - val_accuracy: 0.7031\nEpoch 182/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1649 - accuracy: 0.9375 - val_loss: 1.0596 - val_accuracy: 0.6953\nEpoch 183/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1931 - accuracy: 0.9219 - val_loss: 1.0862 - val_accuracy: 0.6641\nEpoch 184/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1804 - accuracy: 0.9258 - val_loss: 1.0657 - val_accuracy: 0.6719\nEpoch 185/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9492 - val_loss: 1.0316 - val_accuracy: 0.6953\nEpoch 186/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1861 - accuracy: 0.9336 - val_loss: 1.0276 - val_accuracy: 0.6875\nEpoch 187/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1536 - accuracy: 0.9453 - val_loss: 1.0136 - val_accuracy: 0.6953\nEpoch 188/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1799 - accuracy: 0.9258 - val_loss: 1.0480 - val_accuracy: 0.6406\nEpoch 189/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1908 - accuracy: 0.9238 - val_loss: 0.9925 - val_accuracy: 0.7344\nEpoch 190/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1419 - accuracy: 0.9395 - val_loss: 1.0218 - val_accuracy: 0.6953\nEpoch 191/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 0.9414 - val_loss: 1.0745 - val_accuracy: 0.6641\nEpoch 192/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1403 - accuracy: 0.9551 - val_loss: 1.0248 - val_accuracy: 0.6953\nEpoch 193/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1500 - accuracy: 0.9453 - val_loss: 1.0522 - val_accuracy: 0.6641\nEpoch 194/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1832 - accuracy: 0.9277 - val_loss: 1.0639 - val_accuracy: 0.6719\nEpoch 195/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1637 - accuracy: 0.9336 - val_loss: 1.0145 - val_accuracy: 0.7109\nEpoch 196/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1294 - accuracy: 0.9453 - val_loss: 1.0470 - val_accuracy: 0.6953\nEpoch 197/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.9434 - val_loss: 1.0219 - val_accuracy: 0.7109\nEpoch 198/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.2248 - accuracy: 0.9199 - val_loss: 1.0099 - val_accuracy: 0.6875\nEpoch 199/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9512 - val_loss: 1.0404 - val_accuracy: 0.6719\nEpoch 200/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1550 - accuracy: 0.9355 - val_loss: 1.0132 - val_accuracy: 0.7188\nEpoch 201/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1344 - accuracy: 0.9414 - val_loss: 1.0228 - val_accuracy: 0.6875\nEpoch 202/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.9355 - val_loss: 1.0173 - val_accuracy: 0.6953\nEpoch 203/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.9336 - val_loss: 1.0836 - val_accuracy: 0.6641\nEpoch 204/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9609 - val_loss: 1.0711 - val_accuracy: 0.6875\nEpoch 205/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1246 - accuracy: 0.9414 - val_loss: 1.0586 - val_accuracy: 0.6797\nEpoch 206/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1724 - accuracy: 0.9375 - val_loss: 1.0276 - val_accuracy: 0.7109\nEpoch 207/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1349 - accuracy: 0.9551 - val_loss: 1.0071 - val_accuracy: 0.7266\nEpoch 208/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1576 - accuracy: 0.9414 - val_loss: 0.9834 - val_accuracy: 0.7266\nEpoch 209/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1350 - accuracy: 0.9492 - val_loss: 1.0015 - val_accuracy: 0.7109\nEpoch 210/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1300 - accuracy: 0.9590 - val_loss: 1.0360 - val_accuracy: 0.7031\nEpoch 211/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 0.9453 - val_loss: 1.0452 - val_accuracy: 0.7031\nEpoch 212/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.9434 - val_loss: 0.9949 - val_accuracy: 0.7344\nEpoch 213/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.9434 - val_loss: 1.0096 - val_accuracy: 0.7031\nEpoch 214/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1759 - accuracy: 0.9395 - val_loss: 1.0154 - val_accuracy: 0.7188\nEpoch 215/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1125 - accuracy: 0.9551 - val_loss: 0.9935 - val_accuracy: 0.7422\nEpoch 216/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9434 - val_loss: 1.1155 - val_accuracy: 0.6797\nEpoch 217/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1238 - accuracy: 0.9531 - val_loss: 1.0697 - val_accuracy: 0.7109\nEpoch 218/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1871 - accuracy: 0.9238 - val_loss: 1.1726 - val_accuracy: 0.6797\nEpoch 219/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1345 - accuracy: 0.9551 - val_loss: 1.0245 - val_accuracy: 0.7266\nEpoch 220/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9453 - val_loss: 1.0456 - val_accuracy: 0.7266\nEpoch 221/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 0.9473 - val_loss: 1.0766 - val_accuracy: 0.7031\nEpoch 222/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1163 - accuracy: 0.9570 - val_loss: 1.0830 - val_accuracy: 0.7031\nEpoch 223/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1490 - accuracy: 0.9492 - val_loss: 1.0566 - val_accuracy: 0.6953\nEpoch 224/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1685 - accuracy: 0.9297 - val_loss: 1.0550 - val_accuracy: 0.7266\nEpoch 225/5000\n16/16 [==============================] - 0s 7ms/step - loss: 0.1508 - accuracy: 0.9453 - val_loss: 1.1340 - val_accuracy: 0.6719\nEpoch 226/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9629 - val_loss: 1.0792 - val_accuracy: 0.7188\nEpoch 227/5000\n16/16 [==============================] - 0s 8ms/step - loss: 0.1559 - accuracy: 0.9414 - val_loss: 1.1041 - val_accuracy: 0.7109\nEpoch 228/5000\n16/16 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.9492 - val_loss: 1.1362 - val_accuracy: 0.7344\nEpoch 229/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9629 - val_loss: 1.0626 - val_accuracy: 0.7188\nEpoch 230/5000\n16/16 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.9434 - val_loss: 1.1673 - val_accuracy: 0.6875\nEpoch 00230: early stopping\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f9fddb6bc40>"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "model.fit(x=X_train, y=Y_train, epochs=5000, validation_data=(X_test,Y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predictions = model.predict_classes(X_test)\n",
    "Y_predictions = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_indices = np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test_indices, Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test_indices, Y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}